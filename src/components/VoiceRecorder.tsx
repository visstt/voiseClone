import { useState, useRef, useEffect, useCallback } from "react";
import WaveSurfer from "wavesurfer.js";
import "./VoiceRecorder.css";

interface VoiceRecorderProps {
  onAudioRecorded: (audio: Blob) => void;
  onVoiceCloned: (cloned: boolean) => void;
}

const VoiceRecorder: React.FC<VoiceRecorderProps> = ({
  onAudioRecorded,
  onVoiceCloned,
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [audioURL, setAudioURL] = useState<string | null>(null);
  const [recordingTime, setRecordingTime] = useState(0);

  const waveformRef = useRef<HTMLDivElement>(null);
  const realtimeCanvasRef = useRef<HTMLCanvasElement>(null);
  const wavesurferRef = useRef<WaveSurfer | null>(null);
  const timerRef = useRef<number | null>(null);

  // –î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–∞–ª—å–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const animationIdRef = useRef<number | null>(null);
  const isAnimatingRef = useRef<boolean>(false);

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–Ω–∏–º–∞—Ü–∏–∏
  const stopAnimation = useCallback(() => {
    isAnimatingRef.current = false;
    if (animationIdRef.current) {
      cancelAnimationFrame(animationIdRef.current);
      animationIdRef.current = null;
    }
  }, []);

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è –≤–æ–ª–Ω—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
  const drawRealTimeWave = useCallback(() => {
    if (!analyserRef.current || !realtimeCanvasRef.current) {
      console.log("Analyser or canvas not available");
      return;
    }

    const canvas = realtimeCanvasRef.current;
    const canvasCtx = canvas.getContext("2d");
    if (!canvasCtx) {
      console.log("Canvas context not available");
      return;
    }

    const analyser = analyserRef.current;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    console.log("Starting animation loop...");
    isAnimatingRef.current = true;

    const draw = () => {
      if (!isAnimatingRef.current) {
        // –û—á–∏—â–∞–µ–º canvas –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–ø–∏—Å–∏
        canvasCtx.fillStyle = "#141414";
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
        console.log("Animation stopped");
        return;
      }

      animationIdRef.current = requestAnimationFrame(draw);

      // –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–∏ (–ª—É—á—à–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏)
      analyser.getByteTimeDomainData(dataArray);

      // –û—á–∏—â–∞–µ–º –∫–∞–Ω–≤–∞—Å
      canvasCtx.fillStyle = "#141414";
      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

      // –†–∏—Å—É–µ–º –≤–æ–ª–Ω—É –∫–∞–∫ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª–æ—Å–∫–∏ (–∫–∞–∫ –≤ WaveSurfer)
      const barWidth = 4; // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É –ø–æ–ª–æ—Å–æ–∫
      const barGap = 1;
      const totalBars = Math.floor(canvas.width / (barWidth + barGap));
      const step = Math.floor(bufferLength / totalBars);

      let barsDrawn = 0;
      let hasAudio = false;

      // –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ –≤—ã—Å–æ—Ç –¥–ª—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏
      const barHeights: number[] = [];

      // –°–Ω–∞—á–∞–ª–∞ –≤—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –≤—ã—Å–æ—Ç—ã
      for (let i = 0; i < totalBars; i++) {
        const dataIndex = i * step;
        const value = dataArray[dataIndex];

        // –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç —Ü–µ–Ω—Ç—Ä–∞ (128)
        const normalizedValue = Math.abs(value - 128) / 128.0;

        if (normalizedValue > 0.01) hasAudio = true;

        // –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—É—é –∏ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        // –£–º–µ–Ω—å—à–∞–µ–º –±–∞–∑–æ–≤—É—é –ª–∏–Ω–∏—é –∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –∑–≤—É–∫—É
        const baseHeight = 4; // –£–º–µ–Ω—å—à–µ–Ω–Ω–∞—è –±–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è
        const amplifiedValue = Math.pow(normalizedValue, 0.7) * 2.5; // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        const barHeight = Math.max(
          baseHeight,
          amplifiedValue * canvas.height * 0.8
        );

        barHeights.push(barHeight);
      }

      // –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –∫ –≤—ã—Å–æ—Ç–∞–º –¥–ª—è –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
      const smoothedHeights: number[] = [];
      for (let i = 0; i < barHeights.length; i++) {
        let sum = barHeights[i];
        let count = 1;

        // –£—Å—Ä–µ–¥–Ω—è–µ–º —Å —Å–æ—Å–µ–¥–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
        if (i > 0) {
          sum += barHeights[i - 1];
          count++;
        }
        if (i < barHeights.length - 1) {
          sum += barHeights[i + 1];
          count++;
        }

        smoothedHeights.push(sum / count);
      }

      // –¢–µ–ø–µ—Ä—å —Ä–∏—Å—É–µ–º —Å –ø–ª–∞–≤–Ω—ã–º–∏ –≤—ã—Å–æ—Ç–∞–º–∏
      for (let i = 0; i < totalBars; i++) {
        const barHeight = smoothedHeights[i];

        const x = i * (barWidth + barGap);
        const y = (canvas.height - barHeight) / 2;

        // –°–æ–∑–¥–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞
        const gradient = canvasCtx.createLinearGradient(0, y, 0, y + barHeight);
        gradient.addColorStop(0, "#7C3AED");
        gradient.addColorStop(0.5, "#4F46E5");
        gradient.addColorStop(1, "#3B82F6");

        canvasCtx.fillStyle = gradient;

        // –†–∏—Å—É–µ–º –∑–∞–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –¥–ª—è –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω–æ–≥–æ –≤–∏–¥–∞
        const radius = Math.min(barWidth / 2, 2); // –†–∞–¥–∏—É—Å –∑–∞–∫—Ä—É–≥–ª–µ–Ω–∏—è
        canvasCtx.beginPath();
        canvasCtx.roundRect(x, y, barWidth, barHeight, radius);
        canvasCtx.fill();

        barsDrawn++;
      }

      // –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∞—É–¥–∏–æ
      if (hasAudio) {
        console.log(`Audio detected - Drew ${barsDrawn} bars`);
      }
    };

    // –ù–∞—á–∏–Ω–∞–µ–º —Ü–∏–∫–ª –∞–Ω–∏–º–∞—Ü–∏–∏
    draw();
  }, []);

  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
  const initRealtimeVisualization = useCallback(async () => {
    try {
      console.log("Requesting microphone access...");
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      console.log("Microphone access granted");
      streamRef.current = stream;

      const audioContext = new (window.AudioContext ||
        (window as typeof window & { webkitAudioContext: typeof AudioContext })
          .webkitAudioContext)();
      audioContextRef.current = audioContext;

      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048; // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –±–æ–ª—å—à–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏
      analyser.smoothingTimeConstant = 0.8; // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
      analyser.minDecibels = -90; // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ —Ç–∏—Ö–∏–º –∑–≤—É–∫–∞–º
      analyser.maxDecibels = -10; // –†–∞—Å—à–∏—Ä—è–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω
      analyserRef.current = analyser;

      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);

      console.log("Audio context and analyser created");

      // –°–æ–∑–¥–∞–µ–º MediaRecorder –¥–ª—è –∑–∞–ø–∏—Å–∏
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      const audioChunks: Blob[] = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
        const url = URL.createObjectURL(audioBlob);
        setAudioURL(url);
        onAudioRecorded(audioBlob);
        audioChunks.length = 0;
      };

      console.log("MediaRecorder initialized");
      return true;
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:", error);
      return false;
    }
  }, [onAudioRecorded]);

  useEffect(() => {
    // Cleanup –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
    return () => {
      stopAnimation();
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
    };
  }, [stopAnimation]);

  // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ canvas —Ä–∞–∑–º–µ—Ä–æ–≤
  useEffect(() => {
    if (realtimeCanvasRef.current) {
      const canvas = realtimeCanvasRef.current;
      const rect = canvas.getBoundingClientRect();
      canvas.width = rect.width;
      canvas.height = rect.height;
      console.log(`Canvas size set to: ${canvas.width}x${canvas.height}`);
    }
  }, []);

  useEffect(() => {
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WaveSurfer –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
    if (waveformRef.current && audioURL) {
      if (wavesurferRef.current) {
        wavesurferRef.current.destroy();
      }

      wavesurferRef.current = WaveSurfer.create({
        container: waveformRef.current,
        waveColor: "#4F46E5",
        progressColor: "#7C3AED",
        cursorColor: "#EC4899",
        barWidth: 3,
        barRadius: 3,
        height: 80,
        normalize: true,
      });

      wavesurferRef.current.load(audioURL);
    }

    return () => {
      if (wavesurferRef.current) {
        wavesurferRef.current.destroy();
      }
    };
  }, [audioURL]);

  const startRecording = async () => {
    console.log("Attempting to start recording...");

    try {
      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
      const initialized = await initRealtimeVisualization();
      if (!initialized) {
        alert("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é");
        return;
      }

      console.log("Visualization initialized successfully");

      // –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å —Å MediaRecorder
      if (mediaRecorderRef.current) {
        mediaRecorderRef.current.start();
        setIsRecording(true);
        setRecordingTime(0);

        console.log("Starting real-time visualization...");
        // –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        drawRealTimeWave();

        // –¢–∞–π–º–µ—Ä –∑–∞–ø–∏—Å–∏ (–º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥)
        timerRef.current = setInterval(() => {
          setRecordingTime((prev) => {
            if (prev >= 60) {
              stopRecording();
              return 60;
            }
            return prev + 1;
          });
        }, 1000);

        console.log("Recording started with real-time visualization");
      }
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏:", error);
      alert("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É: " + error);
    }
  };

  const stopRecording = () => {
    console.log("Stopping recording...");

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–Ω–∏–º–∞—Ü–∏—é
    stopAnimation();

    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
    }

    setIsRecording(false);

    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    // –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop());
      streamRef.current = null;
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    console.log("Recording stopped and resources cleaned up");
  };

  const playRecording = () => {
    if (wavesurferRef.current) {
      wavesurferRef.current.play();
    }
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, "0")}`;
  };

  return (
    <div className="voice-recorder">
      <div className="app-header">
        <div className="app-icon">üéôÔ∏è</div>
        <h1 className="app-title">VoiceClone</h1>
      </div>

      <div className="app-main">
        <div className="recording-interface">
          <div className="record-button-wrapper">
            <button
              className={`record-button ${isRecording ? "recording" : ""}`}
              onClick={isRecording ? stopRecording : startRecording}
            >
              üéôÔ∏è
            </button>
            <p className="record-status">
              {isRecording ? "Recording..." : "Start recording"}
            </p>
          </div>

          <div
            className={`audio-visualizer ${isRecording ? "visible" : "hidden"}`}
          >
            <canvas
              ref={realtimeCanvasRef}
              className="realtime-waveform"
              width={800}
              height={120}
              style={{
                width: "100%",
                height: "120px",
                backgroundColor: "#141414",
                borderRadius: "8px",
                border: "1px solid #333",
              }}
            />
            {isRecording && (
              <div className="recording-timer">
                {formatTime(recordingTime)} / 1:00
              </div>
            )}
          </div>
        </div>

        {audioURL && !isRecording && (
          <div className="audio-result">
            <div className="result-info">
              <p>Recorded audio ready for playback</p>
            </div>

            <div className="result-actions">
              <button onClick={playRecording} className="action-button primary">
                ‚ñ∂Ô∏è Play Recording
              </button>
            </div>

            <div className="waveform-container">
              <div ref={waveformRef} className="waveform"></div>
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default VoiceRecorder;
